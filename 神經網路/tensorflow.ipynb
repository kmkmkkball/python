{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 範例1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 隨機生成100個數列 type=float32\n",
    "x_data = np.random.rand(100).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 要預測的 weight接近0.1 biases接近0.3\n",
    "y_data = x_data*0.1 + 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create tensopflow structure start ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "## 隨機數列生成 1維 範圍-1到1之間\n",
    "Weights = tf.Variable(tf.random_uniform([1],-1.0,1.0))\n",
    "## 初始值為0 1維\n",
    "biases = tf.Variable(tf.zeros([1]))\n",
    "## y = W*0.1+0.3\n",
    "y = Weights*x_data + biases\n",
    "## 計算預測的y和實際的y的差別\n",
    "loss = tf.reduce_mean(tf.square(y-y_data))\n",
    "## 建立優化器 使用GradientDescentOptimizer 學習效率0.5 一般小於1\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "## 減少誤差 提升參數準確度\n",
    "train = optimizer.minimize(loss)\n",
    "## 上面只是建立 這邊才初始化\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create tensopflow structure end ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把結構激活初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.44348013] [ 0.15806383]\n",
      "20 [ 0.1926955] [ 0.25127953]\n",
      "40 [ 0.12622967] [ 0.28621379]\n",
      "60 [ 0.10742211] [ 0.29609898]\n",
      "80 [ 0.1021002] [ 0.29889616]\n",
      "100 [ 0.10059429] [ 0.29968765]\n",
      "120 [ 0.10016818] [ 0.29991162]\n",
      "140 [ 0.1000476] [ 0.29997501]\n",
      "160 [ 0.10001348] [ 0.29999292]\n",
      "180 [ 0.10000385] [ 0.29999799]\n",
      "200 [ 0.10000108] [ 0.29999945]\n"
     ]
    }
   ],
   "source": [
    "## 神經網路的指針\n",
    "sess = tf.Session()\n",
    "## 指針指向init激活\n",
    "## 重要\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(Weights), sess.run(biases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 範例 Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 一行兩列\n",
    "matrix1 = tf.constant([[3, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 兩行一列\n",
    "matrix2 = tf.constant([[2],[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 矩陣乘法  matrix multiply\n",
    "## np.dot(m1, m2)\n",
    "product = tf.matmul(matrix1, matrix2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = sess.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result2 = sess.run(product)\n",
    "    print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tensorflow 範例 Varible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 如果有定義Varible,就一定要有init=tf.initialize_all_variables(), sess.run(init)\n",
    "state = tf.Variable(0, name = \"counter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter:0\n"
     ]
    }
   ],
   "source": [
    "print(state.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 常量1\n",
    "one = tf.constant(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 新的變量值\n",
    "new_value = tf.add(state, one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 將new_value 這個變量,加載到state\n",
    "update = tf.assign(state, new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "## 一定要有\n",
    "## must have if define varible\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 範例 placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  sess.run 才定義值就用placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 給定type\n",
    "input1 = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input2 = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = tf.multiply(input1, input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(output, feed_dict={input1:[7.],input2:[2.]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 範例 activation function激勵函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 定義一個增加層\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "## 定義權重 隨機變量\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "## 機器學習中 biases 推薦不為0\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "## Weights * x * plus + biases\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "## 如果沒有激活函數\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "## 有的話\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 輸入層 -1到+1之間 300個\n",
    "x_data = np.linspace(-1,1,300)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ],\n",
       "       [-0.99331104],\n",
       "       [-0.98662207],\n",
       "       [-0.97993311],\n",
       "       [-0.97324415],\n",
       "       [-0.96655518],\n",
       "       [-0.95986622],\n",
       "       [-0.95317726],\n",
       "       [-0.94648829],\n",
       "       [-0.93979933],\n",
       "       [-0.93311037],\n",
       "       [-0.9264214 ],\n",
       "       [-0.91973244],\n",
       "       [-0.91304348],\n",
       "       [-0.90635452],\n",
       "       [-0.89966555],\n",
       "       [-0.89297659],\n",
       "       [-0.88628763],\n",
       "       [-0.87959866],\n",
       "       [-0.8729097 ],\n",
       "       [-0.86622074],\n",
       "       [-0.85953177],\n",
       "       [-0.85284281],\n",
       "       [-0.84615385],\n",
       "       [-0.83946488],\n",
       "       [-0.83277592],\n",
       "       [-0.82608696],\n",
       "       [-0.81939799],\n",
       "       [-0.81270903],\n",
       "       [-0.80602007],\n",
       "       [-0.7993311 ],\n",
       "       [-0.79264214],\n",
       "       [-0.78595318],\n",
       "       [-0.77926421],\n",
       "       [-0.77257525],\n",
       "       [-0.76588629],\n",
       "       [-0.75919732],\n",
       "       [-0.75250836],\n",
       "       [-0.7458194 ],\n",
       "       [-0.73913043],\n",
       "       [-0.73244147],\n",
       "       [-0.72575251],\n",
       "       [-0.71906355],\n",
       "       [-0.71237458],\n",
       "       [-0.70568562],\n",
       "       [-0.69899666],\n",
       "       [-0.69230769],\n",
       "       [-0.68561873],\n",
       "       [-0.67892977],\n",
       "       [-0.6722408 ],\n",
       "       [-0.66555184],\n",
       "       [-0.65886288],\n",
       "       [-0.65217391],\n",
       "       [-0.64548495],\n",
       "       [-0.63879599],\n",
       "       [-0.63210702],\n",
       "       [-0.62541806],\n",
       "       [-0.6187291 ],\n",
       "       [-0.61204013],\n",
       "       [-0.60535117],\n",
       "       [-0.59866221],\n",
       "       [-0.59197324],\n",
       "       [-0.58528428],\n",
       "       [-0.57859532],\n",
       "       [-0.57190635],\n",
       "       [-0.56521739],\n",
       "       [-0.55852843],\n",
       "       [-0.55183946],\n",
       "       [-0.5451505 ],\n",
       "       [-0.53846154],\n",
       "       [-0.53177258],\n",
       "       [-0.52508361],\n",
       "       [-0.51839465],\n",
       "       [-0.51170569],\n",
       "       [-0.50501672],\n",
       "       [-0.49832776],\n",
       "       [-0.4916388 ],\n",
       "       [-0.48494983],\n",
       "       [-0.47826087],\n",
       "       [-0.47157191],\n",
       "       [-0.46488294],\n",
       "       [-0.45819398],\n",
       "       [-0.45150502],\n",
       "       [-0.44481605],\n",
       "       [-0.43812709],\n",
       "       [-0.43143813],\n",
       "       [-0.42474916],\n",
       "       [-0.4180602 ],\n",
       "       [-0.41137124],\n",
       "       [-0.40468227],\n",
       "       [-0.39799331],\n",
       "       [-0.39130435],\n",
       "       [-0.38461538],\n",
       "       [-0.37792642],\n",
       "       [-0.37123746],\n",
       "       [-0.36454849],\n",
       "       [-0.35785953],\n",
       "       [-0.35117057],\n",
       "       [-0.34448161],\n",
       "       [-0.33779264],\n",
       "       [-0.33110368],\n",
       "       [-0.32441472],\n",
       "       [-0.31772575],\n",
       "       [-0.31103679],\n",
       "       [-0.30434783],\n",
       "       [-0.29765886],\n",
       "       [-0.2909699 ],\n",
       "       [-0.28428094],\n",
       "       [-0.27759197],\n",
       "       [-0.27090301],\n",
       "       [-0.26421405],\n",
       "       [-0.25752508],\n",
       "       [-0.25083612],\n",
       "       [-0.24414716],\n",
       "       [-0.23745819],\n",
       "       [-0.23076923],\n",
       "       [-0.22408027],\n",
       "       [-0.2173913 ],\n",
       "       [-0.21070234],\n",
       "       [-0.20401338],\n",
       "       [-0.19732441],\n",
       "       [-0.19063545],\n",
       "       [-0.18394649],\n",
       "       [-0.17725753],\n",
       "       [-0.17056856],\n",
       "       [-0.1638796 ],\n",
       "       [-0.15719064],\n",
       "       [-0.15050167],\n",
       "       [-0.14381271],\n",
       "       [-0.13712375],\n",
       "       [-0.13043478],\n",
       "       [-0.12374582],\n",
       "       [-0.11705686],\n",
       "       [-0.11036789],\n",
       "       [-0.10367893],\n",
       "       [-0.09698997],\n",
       "       [-0.090301  ],\n",
       "       [-0.08361204],\n",
       "       [-0.07692308],\n",
       "       [-0.07023411],\n",
       "       [-0.06354515],\n",
       "       [-0.05685619],\n",
       "       [-0.05016722],\n",
       "       [-0.04347826],\n",
       "       [-0.0367893 ],\n",
       "       [-0.03010033],\n",
       "       [-0.02341137],\n",
       "       [-0.01672241],\n",
       "       [-0.01003344],\n",
       "       [-0.00334448],\n",
       "       [ 0.00334448],\n",
       "       [ 0.01003344],\n",
       "       [ 0.01672241],\n",
       "       [ 0.02341137],\n",
       "       [ 0.03010033],\n",
       "       [ 0.0367893 ],\n",
       "       [ 0.04347826],\n",
       "       [ 0.05016722],\n",
       "       [ 0.05685619],\n",
       "       [ 0.06354515],\n",
       "       [ 0.07023411],\n",
       "       [ 0.07692308],\n",
       "       [ 0.08361204],\n",
       "       [ 0.090301  ],\n",
       "       [ 0.09698997],\n",
       "       [ 0.10367893],\n",
       "       [ 0.11036789],\n",
       "       [ 0.11705686],\n",
       "       [ 0.12374582],\n",
       "       [ 0.13043478],\n",
       "       [ 0.13712375],\n",
       "       [ 0.14381271],\n",
       "       [ 0.15050167],\n",
       "       [ 0.15719064],\n",
       "       [ 0.1638796 ],\n",
       "       [ 0.17056856],\n",
       "       [ 0.17725753],\n",
       "       [ 0.18394649],\n",
       "       [ 0.19063545],\n",
       "       [ 0.19732441],\n",
       "       [ 0.20401338],\n",
       "       [ 0.21070234],\n",
       "       [ 0.2173913 ],\n",
       "       [ 0.22408027],\n",
       "       [ 0.23076923],\n",
       "       [ 0.23745819],\n",
       "       [ 0.24414716],\n",
       "       [ 0.25083612],\n",
       "       [ 0.25752508],\n",
       "       [ 0.26421405],\n",
       "       [ 0.27090301],\n",
       "       [ 0.27759197],\n",
       "       [ 0.28428094],\n",
       "       [ 0.2909699 ],\n",
       "       [ 0.29765886],\n",
       "       [ 0.30434783],\n",
       "       [ 0.31103679],\n",
       "       [ 0.31772575],\n",
       "       [ 0.32441472],\n",
       "       [ 0.33110368],\n",
       "       [ 0.33779264],\n",
       "       [ 0.34448161],\n",
       "       [ 0.35117057],\n",
       "       [ 0.35785953],\n",
       "       [ 0.36454849],\n",
       "       [ 0.37123746],\n",
       "       [ 0.37792642],\n",
       "       [ 0.38461538],\n",
       "       [ 0.39130435],\n",
       "       [ 0.39799331],\n",
       "       [ 0.40468227],\n",
       "       [ 0.41137124],\n",
       "       [ 0.4180602 ],\n",
       "       [ 0.42474916],\n",
       "       [ 0.43143813],\n",
       "       [ 0.43812709],\n",
       "       [ 0.44481605],\n",
       "       [ 0.45150502],\n",
       "       [ 0.45819398],\n",
       "       [ 0.46488294],\n",
       "       [ 0.47157191],\n",
       "       [ 0.47826087],\n",
       "       [ 0.48494983],\n",
       "       [ 0.4916388 ],\n",
       "       [ 0.49832776],\n",
       "       [ 0.50501672],\n",
       "       [ 0.51170569],\n",
       "       [ 0.51839465],\n",
       "       [ 0.52508361],\n",
       "       [ 0.53177258],\n",
       "       [ 0.53846154],\n",
       "       [ 0.5451505 ],\n",
       "       [ 0.55183946],\n",
       "       [ 0.55852843],\n",
       "       [ 0.56521739],\n",
       "       [ 0.57190635],\n",
       "       [ 0.57859532],\n",
       "       [ 0.58528428],\n",
       "       [ 0.59197324],\n",
       "       [ 0.59866221],\n",
       "       [ 0.60535117],\n",
       "       [ 0.61204013],\n",
       "       [ 0.6187291 ],\n",
       "       [ 0.62541806],\n",
       "       [ 0.63210702],\n",
       "       [ 0.63879599],\n",
       "       [ 0.64548495],\n",
       "       [ 0.65217391],\n",
       "       [ 0.65886288],\n",
       "       [ 0.66555184],\n",
       "       [ 0.6722408 ],\n",
       "       [ 0.67892977],\n",
       "       [ 0.68561873],\n",
       "       [ 0.69230769],\n",
       "       [ 0.69899666],\n",
       "       [ 0.70568562],\n",
       "       [ 0.71237458],\n",
       "       [ 0.71906355],\n",
       "       [ 0.72575251],\n",
       "       [ 0.73244147],\n",
       "       [ 0.73913043],\n",
       "       [ 0.7458194 ],\n",
       "       [ 0.75250836],\n",
       "       [ 0.75919732],\n",
       "       [ 0.76588629],\n",
       "       [ 0.77257525],\n",
       "       [ 0.77926421],\n",
       "       [ 0.78595318],\n",
       "       [ 0.79264214],\n",
       "       [ 0.7993311 ],\n",
       "       [ 0.80602007],\n",
       "       [ 0.81270903],\n",
       "       [ 0.81939799],\n",
       "       [ 0.82608696],\n",
       "       [ 0.83277592],\n",
       "       [ 0.83946488],\n",
       "       [ 0.84615385],\n",
       "       [ 0.85284281],\n",
       "       [ 0.85953177],\n",
       "       [ 0.86622074],\n",
       "       [ 0.8729097 ],\n",
       "       [ 0.87959866],\n",
       "       [ 0.88628763],\n",
       "       [ 0.89297659],\n",
       "       [ 0.89966555],\n",
       "       [ 0.90635452],\n",
       "       [ 0.91304348],\n",
       "       [ 0.91973244],\n",
       "       [ 0.9264214 ],\n",
       "       [ 0.93311037],\n",
       "       [ 0.93979933],\n",
       "       [ 0.94648829],\n",
       "       [ 0.95317726],\n",
       "       [ 0.95986622],\n",
       "       [ 0.96655518],\n",
       "       [ 0.97324415],\n",
       "       [ 0.97993311],\n",
       "       [ 0.98662207],\n",
       "       [ 0.99331104],\n",
       "       [ 1.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 增加噪點 更像真實數據\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06332415],\n",
       "       [ 0.05652018],\n",
       "       [ 0.04823826],\n",
       "       [ 0.0398254 ],\n",
       "       [ 0.04524938],\n",
       "       [ 0.09735696],\n",
       "       [-0.02073219],\n",
       "       [-0.00611824],\n",
       "       [-0.02503094],\n",
       "       [-0.02423715],\n",
       "       [-0.06443504],\n",
       "       [-0.07731952],\n",
       "       [ 0.05361295],\n",
       "       [-0.03649031],\n",
       "       [-0.05879509],\n",
       "       [-0.05317363],\n",
       "       [-0.05962982],\n",
       "       [-0.01119417],\n",
       "       [ 0.05750726],\n",
       "       [ 0.01842044],\n",
       "       [ 0.01846078],\n",
       "       [ 0.01913487],\n",
       "       [-0.01504898],\n",
       "       [-0.0300913 ],\n",
       "       [ 0.01477335],\n",
       "       [-0.01223365],\n",
       "       [ 0.02096344],\n",
       "       [-0.05290887],\n",
       "       [-0.01800538],\n",
       "       [ 0.01114596],\n",
       "       [ 0.02516683],\n",
       "       [ 0.06839273],\n",
       "       [-0.08364587],\n",
       "       [-0.04351759],\n",
       "       [ 0.10631485],\n",
       "       [-0.00338694],\n",
       "       [-0.01333746],\n",
       "       [-0.01871476],\n",
       "       [ 0.14428176],\n",
       "       [-0.01612948],\n",
       "       [ 0.01646155],\n",
       "       [ 0.03784786],\n",
       "       [ 0.02393427],\n",
       "       [ 0.05857249],\n",
       "       [ 0.05621182],\n",
       "       [ 0.03292948],\n",
       "       [-0.04478401],\n",
       "       [ 0.03808635],\n",
       "       [-0.09051833],\n",
       "       [-0.00180407],\n",
       "       [-0.01385952],\n",
       "       [-0.02686157],\n",
       "       [-0.04390362],\n",
       "       [-0.00545724],\n",
       "       [-0.02662719],\n",
       "       [-0.06759795],\n",
       "       [ 0.00828737],\n",
       "       [ 0.0883646 ],\n",
       "       [ 0.01002646],\n",
       "       [-0.09123008],\n",
       "       [-0.10957918],\n",
       "       [-0.0131604 ],\n",
       "       [-0.0343996 ],\n",
       "       [-0.00901497],\n",
       "       [ 0.13121236],\n",
       "       [-0.00078242],\n",
       "       [-0.00286141],\n",
       "       [ 0.08483483],\n",
       "       [-0.01211161],\n",
       "       [ 0.01492902],\n",
       "       [-0.07542634],\n",
       "       [-0.06547482],\n",
       "       [ 0.00884007],\n",
       "       [-0.06052979],\n",
       "       [-0.02033036],\n",
       "       [ 0.00691134],\n",
       "       [ 0.01629793],\n",
       "       [-0.02582312],\n",
       "       [ 0.05594763],\n",
       "       [-0.02556762],\n",
       "       [-0.00368517],\n",
       "       [-0.05708442],\n",
       "       [-0.05450811],\n",
       "       [-0.02831604],\n",
       "       [-0.06254623],\n",
       "       [-0.03247564],\n",
       "       [-0.01104442],\n",
       "       [-0.00801387],\n",
       "       [-0.02521234],\n",
       "       [ 0.00154405],\n",
       "       [ 0.05797754],\n",
       "       [ 0.023885  ],\n",
       "       [-0.03674562],\n",
       "       [ 0.05337822],\n",
       "       [ 0.05690973],\n",
       "       [ 0.03438751],\n",
       "       [-0.07373785],\n",
       "       [ 0.01936549],\n",
       "       [-0.01046651],\n",
       "       [-0.05446152],\n",
       "       [ 0.12131317],\n",
       "       [-0.02114382],\n",
       "       [-0.079175  ],\n",
       "       [-0.02315698],\n",
       "       [-0.05391729],\n",
       "       [-0.01390041],\n",
       "       [ 0.04076011],\n",
       "       [-0.0150781 ],\n",
       "       [ 0.0183187 ],\n",
       "       [-0.02248711],\n",
       "       [ 0.03348564],\n",
       "       [-0.06240935],\n",
       "       [ 0.02821719],\n",
       "       [ 0.0202931 ],\n",
       "       [ 0.01460165],\n",
       "       [ 0.04462352],\n",
       "       [ 0.07576035],\n",
       "       [ 0.11363487],\n",
       "       [ 0.08710571],\n",
       "       [-0.02731488],\n",
       "       [ 0.02820409],\n",
       "       [ 0.04035973],\n",
       "       [ 0.10317633],\n",
       "       [ 0.0071388 ],\n",
       "       [-0.00730571],\n",
       "       [-0.01930876],\n",
       "       [-0.06415204],\n",
       "       [ 0.07567732],\n",
       "       [-0.02339545],\n",
       "       [ 0.0032929 ],\n",
       "       [ 0.01364241],\n",
       "       [ 0.04279736],\n",
       "       [-0.04633849],\n",
       "       [ 0.00613703],\n",
       "       [ 0.03161796],\n",
       "       [-0.0197159 ],\n",
       "       [ 0.06115843],\n",
       "       [-0.0168967 ],\n",
       "       [ 0.05000507],\n",
       "       [-0.08130221],\n",
       "       [-0.02839084],\n",
       "       [ 0.05809873],\n",
       "       [ 0.02007334],\n",
       "       [-0.00107631],\n",
       "       [ 0.01515238],\n",
       "       [-0.06047494],\n",
       "       [-0.02906734],\n",
       "       [ 0.01089792],\n",
       "       [-0.00417698],\n",
       "       [-0.01389743],\n",
       "       [ 0.10576669],\n",
       "       [-0.0262148 ],\n",
       "       [-0.03644966],\n",
       "       [-0.01365284],\n",
       "       [ 0.07336121],\n",
       "       [ 0.04444189],\n",
       "       [-0.00859869],\n",
       "       [-0.03509872],\n",
       "       [ 0.00023502],\n",
       "       [ 0.09262638],\n",
       "       [-0.03089536],\n",
       "       [-0.04603723],\n",
       "       [-0.04534598],\n",
       "       [-0.06157396],\n",
       "       [ 0.00075888],\n",
       "       [ 0.03989003],\n",
       "       [ 0.04082186],\n",
       "       [-0.04093689],\n",
       "       [ 0.02967358],\n",
       "       [ 0.03925504],\n",
       "       [-0.01483674],\n",
       "       [-0.06081182],\n",
       "       [ 0.01470979],\n",
       "       [-0.08744772],\n",
       "       [-0.07645792],\n",
       "       [ 0.04858384],\n",
       "       [ 0.108288  ],\n",
       "       [-0.000462  ],\n",
       "       [ 0.00957654],\n",
       "       [-0.05880852],\n",
       "       [ 0.07882461],\n",
       "       [-0.04461154],\n",
       "       [-0.0124644 ],\n",
       "       [ 0.04599691],\n",
       "       [-0.02625592],\n",
       "       [ 0.07097183],\n",
       "       [ 0.00522448],\n",
       "       [ 0.07367609],\n",
       "       [-0.05370454],\n",
       "       [ 0.0336272 ],\n",
       "       [ 0.0228407 ],\n",
       "       [-0.04230058],\n",
       "       [-0.01572521],\n",
       "       [-0.05387536],\n",
       "       [ 0.08025209],\n",
       "       [-0.07520557],\n",
       "       [-0.00474359],\n",
       "       [-0.03803899],\n",
       "       [ 0.05303464],\n",
       "       [-0.03356261],\n",
       "       [ 0.08297178],\n",
       "       [ 0.00562611],\n",
       "       [ 0.00430789],\n",
       "       [-0.05518094],\n",
       "       [ 0.02347057],\n",
       "       [-0.01470789],\n",
       "       [-0.0639426 ],\n",
       "       [-0.11082274],\n",
       "       [ 0.0760449 ],\n",
       "       [ 0.06075241],\n",
       "       [-0.04378313],\n",
       "       [ 0.00933446],\n",
       "       [-0.03044091],\n",
       "       [ 0.08980577],\n",
       "       [ 0.02149191],\n",
       "       [ 0.05031247],\n",
       "       [-0.04681224],\n",
       "       [-0.11200502],\n",
       "       [ 0.10141588],\n",
       "       [-0.03365988],\n",
       "       [ 0.03291631],\n",
       "       [-0.01870393],\n",
       "       [ 0.03623888],\n",
       "       [-0.00671909],\n",
       "       [ 0.07219137],\n",
       "       [-0.01658553],\n",
       "       [ 0.02543467],\n",
       "       [ 0.03240657],\n",
       "       [-0.01629138],\n",
       "       [ 0.03555771],\n",
       "       [-0.01110608],\n",
       "       [ 0.04307399],\n",
       "       [ 0.02043067],\n",
       "       [ 0.03846602],\n",
       "       [-0.09294323],\n",
       "       [ 0.00493233],\n",
       "       [ 0.03057888],\n",
       "       [-0.04372379],\n",
       "       [-0.0235444 ],\n",
       "       [ 0.00997457],\n",
       "       [ 0.03719158],\n",
       "       [-0.09896467],\n",
       "       [-0.04909542],\n",
       "       [ 0.04083192],\n",
       "       [-0.02018808],\n",
       "       [ 0.0718716 ],\n",
       "       [-0.0027396 ],\n",
       "       [ 0.05591649],\n",
       "       [ 0.00735276],\n",
       "       [-0.00794533],\n",
       "       [ 0.01556931],\n",
       "       [ 0.00207994],\n",
       "       [ 0.00043501],\n",
       "       [-0.04467712],\n",
       "       [-0.05362898],\n",
       "       [ 0.03220907],\n",
       "       [-0.03441333],\n",
       "       [-0.03684255],\n",
       "       [-0.08194566],\n",
       "       [ 0.04895415],\n",
       "       [ 0.01685879],\n",
       "       [ 0.01306987],\n",
       "       [ 0.01679151],\n",
       "       [-0.04298049],\n",
       "       [ 0.00876396],\n",
       "       [ 0.03361409],\n",
       "       [-0.04578584],\n",
       "       [-0.0374254 ],\n",
       "       [ 0.01646024],\n",
       "       [-0.06201152],\n",
       "       [ 0.06374083],\n",
       "       [ 0.01434684],\n",
       "       [ 0.00450803],\n",
       "       [-0.00709625],\n",
       "       [ 0.02205958],\n",
       "       [-0.06451517],\n",
       "       [ 0.00820391],\n",
       "       [-0.01642245],\n",
       "       [ 0.03584707],\n",
       "       [-0.09526168],\n",
       "       [-0.03730615],\n",
       "       [ 0.07193599],\n",
       "       [ 0.04219956],\n",
       "       [-0.06029775],\n",
       "       [ 0.02148551],\n",
       "       [-0.01157645],\n",
       "       [-0.03127   ],\n",
       "       [ 0.01303303],\n",
       "       [ 0.04732794],\n",
       "       [ 0.06492876],\n",
       "       [ 0.04546309],\n",
       "       [ 0.07231438],\n",
       "       [ 0.07518736],\n",
       "       [-0.01655287],\n",
       "       [ 0.04637659],\n",
       "       [ 0.12728579],\n",
       "       [-0.0283582 ],\n",
       "       [-0.00761204],\n",
       "       [-0.00093772],\n",
       "       [ 0.08497004]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 輸出層 x的2次方-0.5 +噪點\n",
    "y_data = np.square(x_data) - 0.5 + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43667585],\n",
       "       [ 0.54318699],\n",
       "       [ 0.52166137],\n",
       "       [ 0.5000943 ],\n",
       "       [ 0.49245355],\n",
       "       [ 0.53158588],\n",
       "       [ 0.40061097],\n",
       "       [ 0.40242864],\n",
       "       [ 0.37080915],\n",
       "       [ 0.35898563],\n",
       "       [ 0.30625992],\n",
       "       [ 0.2809371 ],\n",
       "       [ 0.39952071],\n",
       "       [ 0.29715809],\n",
       "       [ 0.26268341],\n",
       "       [ 0.25622448],\n",
       "       [ 0.23777737],\n",
       "       [ 0.27431159],\n",
       "       [ 0.33120107],\n",
       "       [ 0.28039178],\n",
       "       [ 0.26879914],\n",
       "       [ 0.25792974],\n",
       "       [ 0.21229188],\n",
       "       [ 0.18588503],\n",
       "       [ 0.21947463],\n",
       "       [ 0.18128209],\n",
       "       [ 0.2033831 ],\n",
       "       [ 0.1185042 ],\n",
       "       [ 0.14249059],\n",
       "       [ 0.16081431],\n",
       "       [ 0.16409704],\n",
       "       [ 0.19667429],\n",
       "       [ 0.03407653],\n",
       "       [ 0.06373512],\n",
       "       [ 0.20318737],\n",
       "       [ 0.08319487],\n",
       "       [ 0.06304312],\n",
       "       [ 0.04755407],\n",
       "       [ 0.20052834],\n",
       "       [ 0.03018432],\n",
       "       [ 0.05293206],\n",
       "       [ 0.06456457],\n",
       "       [ 0.04098665],\n",
       "       [ 0.06605003],\n",
       "       [ 0.05420401],\n",
       "       [ 0.02152581],\n",
       "       [-0.06549407],\n",
       "       [ 0.00815939],\n",
       "       [-0.12957271],\n",
       "       [-0.04989638],\n",
       "       [-0.07090027],\n",
       "       [-0.09276128],\n",
       "       [-0.1185728 ],\n",
       "       [-0.08880642],\n",
       "       [-0.11856688],\n",
       "       [-0.16803866],\n",
       "       [-0.10056488],\n",
       "       [-0.02880971],\n",
       "       [-0.11538041],\n",
       "       [-0.22478004],\n",
       "       [-0.25118274],\n",
       "       [-0.16272808],\n",
       "       [-0.19184191],\n",
       "       [-0.17424243],\n",
       "       [-0.04171076],\n",
       "       [-0.18131172],\n",
       "       [-0.1909074 ],\n",
       "       [-0.11063837],\n",
       "       [-0.21492254],\n",
       "       [-0.19513015],\n",
       "       [-0.29264427],\n",
       "       [-0.28976202],\n",
       "       [-0.22242692],\n",
       "       [-0.29868708],\n",
       "       [-0.26528847],\n",
       "       [-0.2447581 ],\n",
       "       [-0.24199336],\n",
       "       [-0.29064678],\n",
       "       [-0.21531891],\n",
       "       [-0.30318755],\n",
       "       [-0.28756902],\n",
       "       [-0.3471427 ],\n",
       "       [-0.35065133],\n",
       "       [-0.33045472],\n",
       "       [-0.37059088],\n",
       "       [-0.34633678],\n",
       "       [-0.33063257],\n",
       "       [-0.33323954],\n",
       "       [-0.35598605],\n",
       "       [-0.33468821],\n",
       "       [-0.28362378],\n",
       "       [-0.32299591],\n",
       "       [-0.38881663],\n",
       "       [-0.3037934 ],\n",
       "       [-0.30527302],\n",
       "       [-0.33271689],\n",
       "       [-0.44567441],\n",
       "       [-0.35731374],\n",
       "       [-0.39179893],\n",
       "       [-0.44035765],\n",
       "       [-0.26905719],\n",
       "       [-0.41589891],\n",
       "       [-0.47822535],\n",
       "       [-0.42641309],\n",
       "       [-0.4612897 ],\n",
       "       [-0.42529961],\n",
       "       [-0.37457641],\n",
       "       [-0.43426244],\n",
       "       [-0.404624  ],\n",
       "       [-0.44909867],\n",
       "       [-0.3967053 ],\n",
       "       [-0.49609018],\n",
       "       [-0.40886405],\n",
       "       [-0.42009906],\n",
       "       [-0.42901195],\n",
       "       [-0.40212204],\n",
       "       [-0.37402768],\n",
       "       [-0.33910615],\n",
       "       [-0.36849881],\n",
       "       [-0.48569342],\n",
       "       [-0.43285899],\n",
       "       [-0.42329839],\n",
       "       [-0.36298736],\n",
       "       [-0.46144097],\n",
       "       [-0.47821207],\n",
       "       [-0.49245224],\n",
       "       [-0.53944315],\n",
       "       [-0.40167192],\n",
       "       [-0.50271336],\n",
       "       [-0.47790417],\n",
       "       [-0.46934436],\n",
       "       [-0.44188961],\n",
       "       [-0.53263618],\n",
       "       [-0.4816819 ],\n",
       "       [-0.45763272],\n",
       "       [-0.51030884],\n",
       "       [-0.4306873 ],\n",
       "       [-0.50990572],\n",
       "       [-0.44407777],\n",
       "       [-0.57636938],\n",
       "       [-0.52435285],\n",
       "       [-0.43866864],\n",
       "       [-0.47740991],\n",
       "       [-0.49918595],\n",
       "       [-0.48349417],\n",
       "       [-0.55956891],\n",
       "       [-0.52851925],\n",
       "       [-0.48882244],\n",
       "       [-0.50407631],\n",
       "       [-0.51388624],\n",
       "       [-0.39422213],\n",
       "       [-0.52611413],\n",
       "       [-0.53617002],\n",
       "       [-0.51310475],\n",
       "       [-0.42573276],\n",
       "       [-0.45420466],\n",
       "       [-0.50670833],\n",
       "       [-0.53258197],\n",
       "       [-0.49653235],\n",
       "       [-0.40333564],\n",
       "       [-0.52596253],\n",
       "       [-0.54012007],\n",
       "       [-0.538355  ],\n",
       "       [-0.55341969],\n",
       "       [-0.48983407],\n",
       "       [-0.44936065],\n",
       "       [-0.44699707],\n",
       "       [-0.52723458],\n",
       "       [-0.45501339],\n",
       "       [-0.44373173],\n",
       "       [-0.49603382],\n",
       "       [-0.54012973],\n",
       "       [-0.46263946],\n",
       "       [-0.56273882],\n",
       "       [-0.5496014 ],\n",
       "       [-0.42232253],\n",
       "       [-0.36029177],\n",
       "       [-0.46662569],\n",
       "       [-0.45408159],\n",
       "       [-0.5198716 ],\n",
       "       [-0.37955393],\n",
       "       [-0.50021606],\n",
       "       [-0.46520542],\n",
       "       [-0.40379113],\n",
       "       [-0.47300148],\n",
       "       [-0.37264178],\n",
       "       [-0.43516768],\n",
       "       [-0.36340515],\n",
       "       [-0.48738537],\n",
       "       [-0.39656374],\n",
       "       [-0.40377086],\n",
       "       [-0.46524328],\n",
       "       [-0.43490956],\n",
       "       [-0.46921188],\n",
       "       [-0.33114711],\n",
       "       [-0.48257797],\n",
       "       [-0.4079997 ],\n",
       "       [-0.43708934],\n",
       "       [-0.34172045],\n",
       "       [-0.42393296],\n",
       "       [-0.30292436],\n",
       "       [-0.37570632],\n",
       "       [-0.37237134],\n",
       "       [-0.42711749],\n",
       "       [-0.34363383],\n",
       "       [-0.37689064],\n",
       "       [-0.42111422],\n",
       "       [-0.46289375],\n",
       "       [-0.27083601],\n",
       "       [-0.28084891],\n",
       "       [-0.38001538],\n",
       "       [-0.32143925],\n",
       "       [-0.35566657],\n",
       "       [-0.22978238],\n",
       "       [-0.29236924],\n",
       "       [-0.25773219],\n",
       "       [-0.34895092],\n",
       "       [-0.40814824],\n",
       "       [-0.1886424 ],\n",
       "       [-0.31754373],\n",
       "       [-0.24470363],\n",
       "       [-0.28997047],\n",
       "       [-0.22858478],\n",
       "       [-0.26501038],\n",
       "       [-0.17947808],\n",
       "       [-0.26154364],\n",
       "       [-0.21272262],\n",
       "       [-0.19886041],\n",
       "       [-0.24057858],\n",
       "       [-0.18166022],\n",
       "       [-0.22116525],\n",
       "       [-0.15973694],\n",
       "       [-0.17504253],\n",
       "       [-0.14957997],\n",
       "       [-0.27347253],\n",
       "       [-0.16799079],\n",
       "       [-0.13464858],\n",
       "       [-0.2011661 ],\n",
       "       [-0.17311208],\n",
       "       [-0.13162899],\n",
       "       [-0.09635838],\n",
       "       [-0.22437154],\n",
       "       [-0.16626972],\n",
       "       [-0.06802033],\n",
       "       [-0.12062879],\n",
       "       [-0.02006808],\n",
       "       [-0.08608878],\n",
       "       [-0.01875269],\n",
       "       [-0.05854695],\n",
       "       [-0.06498608],\n",
       "       [-0.03252299],\n",
       "       [-0.03697444],\n",
       "       [-0.02949194],\n",
       "       [-0.06538718],\n",
       "       [-0.06503265],\n",
       "       [ 0.03020127],\n",
       "       [-0.02693579],\n",
       "       [-0.01979016],\n",
       "       [-0.05522895],\n",
       "       [ 0.08542465],\n",
       "       [ 0.06317259],\n",
       "       [ 0.06931644],\n",
       "       [ 0.08306034],\n",
       "       [ 0.03340008],\n",
       "       [ 0.09534577],\n",
       "       [ 0.13048661],\n",
       "       [ 0.06146688],\n",
       "       [ 0.080297  ],\n",
       "       [ 0.14474181],\n",
       "       [ 0.07691869],\n",
       "       [ 0.21340918],\n",
       "       [ 0.17484281],\n",
       "       [ 0.1759211 ],\n",
       "       [ 0.17532341],\n",
       "       [ 0.21557531],\n",
       "       [ 0.14018612],\n",
       "       [ 0.22418024],\n",
       "       [ 0.21091841],\n",
       "       [ 0.27464194],\n",
       "       [ 0.15507668],\n",
       "       [ 0.2246652 ],\n",
       "       [ 0.3456298 ],\n",
       "       [ 0.32770532],\n",
       "       [ 0.23710943],\n",
       "       [ 0.33088361],\n",
       "       [ 0.30990205],\n",
       "       [ 0.3023784 ],\n",
       "       [ 0.3589408 ],\n",
       "       [ 0.40558456],\n",
       "       [ 0.43562372],\n",
       "       [ 0.42868588],\n",
       "       [ 0.46815447],\n",
       "       [ 0.48373424],\n",
       "       [ 0.40479029],\n",
       "       [ 0.48060551],\n",
       "       [ 0.57448996],\n",
       "       [ 0.4319107 ],\n",
       "       [ 0.46581108],\n",
       "       [ 0.4857291 ],\n",
       "       [ 0.58497004]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## None就是接受任何型態的值 屬性1\n",
    "xs = tf.placeholder(tf.float32, [None, 1])\n",
    "ys = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 隱藏層 input = 1 output = 10\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 輸出層 input = 10 output = 1\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 與真實值的差別\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                     reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 訓練 學習效率0.1 誤差越小\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "## 初始\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.306286\n",
      "0.00716604\n",
      "0.00642072\n",
      "0.00610944\n",
      "0.00588096\n",
      "0.00570199\n",
      "0.00553978\n",
      "0.00538861\n",
      "0.00525355\n",
      "0.00511424\n",
      "0.00495895\n",
      "0.00480486\n",
      "0.0046583\n",
      "0.00450028\n",
      "0.00435299\n",
      "0.00423944\n",
      "0.00415345\n",
      "0.00408154\n",
      "0.00401196\n",
      "0.00394517\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    # training\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        # to see the step improvement\n",
    "        print(sess.run(loss, feed_dict={xs: x_data, ys: y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 範例 plot result結果可視化 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12234ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "\n",
    "# Make up some real data\n",
    "x_data = np.linspace(-1,1,300)[:, np.newaxis]\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 1])\n",
    "ys = tf.placeholder(tf.float32, [None, 1])\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "# the error between prediciton and real data\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                     reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# important step\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "# 2017-03-02 if using tensorflow >= 0.12\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# plot the real data\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(x_data, y_data)\n",
    "## 連續plot\n",
    "plt.ion()\n",
    "## show plot\n",
    "plt.show()\n",
    "\n",
    "for i in range(1000):\n",
    "    # training\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        # to visualize the result and improvement\n",
    "        try:\n",
    "            ax.lines.remove(lines[0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        prediction_value = sess.run(prediction, feed_dict={xs: x_data})\n",
    "        # plot the prediction\n",
    "        lines = ax.plot(x_data, prediction_value, \"r-\", lw=5)\n",
    "        plt.pause(0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tensorflow 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name='W')\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b')\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "with tf.name_scope('inputs'):\n",
    "    xs = tf.placeholder(tf.float32, [None, 1], name='x_input')\n",
    "    ys = tf.placeholder(tf.float32, [None, 1], name='y_input')\n",
    "\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "# the error between prediciton and real data\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                                        reduction_indices=[1]))\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# tf.train.SummaryWriter soon be deprecated, use following\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:  # tensorflow version < 0.12\n",
    "    writer = tf.train.SummaryWriter('logs/', sess.graph)\n",
    "else: # tensorflow version >= 0.12\n",
    "    writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "# 2017-03-02 if using tensorflow >= 0.12\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# direct to the local dir and run this in terminal:\n",
    "## 在logs資料夾同一層開CMD\n",
    "# $ tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, n_layer, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    layer_name = 'layer%s' % n_layer\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name='W')\n",
    "            tf.summary.histogram(layer_name + '/weights', Weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b')\n",
    "            tf.summary.histogram(layer_name + '/biases', biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "        tf.summary.histogram(layer_name + '/outputs', outputs)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# Make up some real data\n",
    "x_data = np.linspace(-1, 1, 300)[:, np.newaxis]\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "with tf.name_scope('inputs'):\n",
    "    xs = tf.placeholder(tf.float32, [None, 1], name='x_input')\n",
    "    ys = tf.placeholder(tf.float32, [None, 1], name='y_input')\n",
    "\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, n_layer=1, activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, n_layer=2, activation_function=None)\n",
    "\n",
    "# the error between prediciton and real data\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                                        reduction_indices=[1]))\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        result = sess.run(merged,\n",
    "                          feed_dict={xs: x_data, ys: y_data})\n",
    "        writer.add_summary(result, i)\n",
    "\n",
    "# direct to the local dir and run this in terminal:\n",
    "# $ tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 範例 classification 分類學習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "0.0793\n",
      "0.6361\n",
      "0.7305\n",
      "0.7793\n",
      "0.8055\n",
      "0.8166\n",
      "0.8334\n",
      "0.8343\n",
      "0.8466\n",
      "0.8508\n",
      "0.856\n",
      "0.8569\n",
      "0.8617\n",
      "0.8644\n",
      "0.8635\n",
      "0.8696\n",
      "0.869\n",
      "0.8722\n",
      "0.8707\n",
      "0.8728\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# number 1 to 10 data\n",
    "## 如果沒有會自動下載\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None,):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1,)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b,)\n",
    "    return outputs\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    return result\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 784]) # 28x28\n",
    "## 如果是1>[1000000000], 如果是2>[01000000000],所以有10個\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# add output layer\n",
    "## classification可以用softmax\n",
    "prediction = add_layer(xs, 784, 10,  activation_function=tf.nn.softmax)\n",
    "\n",
    "# the error between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))  # loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "# important step\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "# 2017-03-02 if using tensorflow >= 0.12\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    ## 100個X,Y的sample\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy(\n",
    "            ## 用test Data\n",
    "            mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
